# -*- coding: utf-8 -*-
"""run_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U9rkGRjGg1cfoheSmhp9FZVM-3SDC9Hi

# Firstly we import the libraries and load the dataset from the pre-processing_scriptie.py script
"""

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM, NllbTokenizer
import torch
from tqdm import tqdm
import nltk
from nltk.translate.bleu_score import corpus_bleu
from evaluate import load
import tensorflow as tf
tf.config.set_visible_devices([], 'GPU')  # Hides GPUs from TensorFlow only


# Download necessary NLTK data
nltk.download('punkt')

# load the pre-processed datasets that were previously saved
with open("preprocessed_dutch.txt", "r", encoding="utf-8") as f:
    dutch_sentences = f.read().splitlines()
with open("preprocessed_english.txt", "r", encoding="utf-8") as f:
    english_sentences = f.read().splitlines()

"""# temporarily can later be removed and moved


"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# First we load in the MarianMT model
tokenizer_marianMT = AutoTokenizer.from_pretrained("Helsinki-NLP/opus-mt-nl-en")
MarianMT = AutoModelForSeq2SeqLM.from_pretrained("Helsinki-NLP/opus-mt-nl-en")

# Second we load in the Facebook-NLLB model
tokenizer_facebook = NllbTokenizer.from_pretrained("facebook/nllb-200-distilled-600M")
Facebook_NLLB = AutoModelForSeq2SeqLM.from_pretrained("facebook/nllb-200-distilled-600M")

# Lastly we load in the TOWER model
tokenizer_tower = AutoTokenizer.from_pretrained("Unbabel/TowerInstruct-7B-v0.2")
TOWER = AutoModelForCausalLM.from_pretrained("Unbabel/TowerInstruct-7B-v0.2")

MarianMT = MarianMT.to(device)
Facebook_NLLB = Facebook_NLLB.to(device)
TOWER = TOWER.to(device)

models = {"marian": MarianMT, "nllb": Facebook_NLLB, "tower": TOWER}
tokenizers = {"marian": tokenizer_marianMT, "nllb": tokenizer_facebook, "tower": tokenizer_tower}
print("Model check:")
print(f"- MarianMT: {MarianMT.device}")
print(f"- Facebook_NLLB: {Facebook_NLLB.device}")
print(f"- TOWER: {TOWER.device}")

"""# We first define the evaluation metrics"""

bleu = load("bleu")
bleurt = load("bleurt", config_name="bleurt-tiny-128")
comet = load("comet")
chrf = load("chrf")

def calculate_bleu(predictions, references):
    return bleu.compute(predictions=predictions, references=references)

def calculate_bleurt(predictions, references):
    return bleurt.compute(predictions=predictions, references=references)

def calculate_comet(predictions, references, sources):
    return comet.compute(predictions=predictions, references=references, sources=sources)

def calculate_chrf(predictions, references):
    return chrf.compute(predictions=predictions, references=references)

"""# We then run zero-shot on the models for Dutch->English"""

def perform_zero_shot(models, tokenizers, sentences):
    results = {"marian": [], "nllb" : [], "tower": []}
    for sentence in tqdm(sentences, desc="Zero-shot Translation"):
        # MarianMT
        inputs = tokenizers["marian"](sentence, return_tensors="pt", padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}
        outputs = models["marian"].generate(**inputs)
        results["marian"].append(tokenizers["marian"].decode(outputs[0], skip_special_tokens=True))


        # NLLB
        tokenizers["nllb"].src_lang = "nld_Latn"
        inputs = tokenizers["nllb"](sentence, return_tensors="pt", padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}
        forced_bos_token_id = tokenizers["nllb"].convert_tokens_to_ids(">>eng_Latn<<")
        outputs = models["nllb"].generate(**inputs, forced_bos_token_id=forced_bos_token_id)
        results["nllb"].append(tokenizers["nllb"].decode(outputs[0], skip_special_tokens=True))


        # TOWER
        prompt = f"Translate from Dutch to English: {sentence}"
        inputs = tokenizers["tower"](prompt, return_tensors="pt", padding=True)
        inputs = {key: value.to(device) for key, value in inputs.items()}
        outputs = models["tower"].generate(**inputs, max_new_tokens=100, pad_token_id=tokenizers["tower"].eos_token_id)
        results["tower"].append(tokenizers["tower"].decode(outputs[0], skip_special_tokens=True).replace(prompt, "").strip())

    return results

sample_size = 10 # Reduced sample size for demonstration
sample_dutch_sentences = dutch_sentences[:sample_size]
sample_english_sentences = english_sentences[:sample_size]
results = perform_zero_shot(models, tokenizers, sample_dutch_sentences)

print("\n--- Sample Translations ---")
for i, sentence in enumerate(sample_dutch_sentences):
    print(f"\n?? Sentence {i+1}")
    print(f"?? Dutch:    {sentence}")
    print(f"?? Marian:   {results['marian'][i]}")
    print(f"?? NLLB:     {results['nllb'][i]}")
    print(f"?? Tower:    {results['tower'][i]}")

print("\n--- Evaluation Metrics ---")

marian_predictions = results['marian']
nllb_predictions = results['nllb']
tower_predictions = results['tower']

# BLEU
bleu_marian = calculate_bleu(marian_predictions, [[ref] for ref in sample_english_sentences])
bleu_nllb = calculate_bleu(nllb_predictions, [[ref] for ref in sample_english_sentences])
bleu_tower = calculate_bleu(tower_predictions, [[ref] for ref in sample_english_sentences])
print(f"\nBLEU:")
print(f"- MarianMT: {bleu_marian}")
print(f"- NLLB:     {bleu_nllb}")
print(f"- Tower:    {bleu_tower}")

# BLEURT
bleurt_marian = calculate_bleurt(marian_predictions, sample_english_sentences)
bleurt_nllb = calculate_bleurt(nllb_predictions, sample_english_sentences)
bleurt_tower = calculate_bleurt(tower_predictions, sample_english_sentences)
print(f"\nBLEURT:")
print(f"- MarianMT: {bleurt_marian}")
print(f"- NLLB:     {bleurt_nllb}")
print(f"- Tower:    {bleurt_tower}")

# COMET
comet_marian = calculate_comet(marian_predictions, sample_english_sentences, sample_dutch_sentences)
comet_nllb = calculate_comet(nllb_predictions, sample_english_sentences, sample_dutch_sentences)
comet_tower = calculate_comet(tower_predictions, sample_english_sentences, sample_dutch_sentences)
print(f"\nCOMET:")
print(f"- MarianMT: {comet_marian}")
print(f"- NLLB:     {comet_nllb}")
print(f"- Tower:    {comet_tower}")

# CHRF
chrf_marian = calculate_chrf(marian_predictions, sample_english_sentences)
chrf_nllb = calculate_chrf(nllb_predictions, sample_english_sentences)
chrf_tower = calculate_chrf(tower_predictions, sample_english_sentences)
print(f"\nCHRF:")
print(f"- MarianMT: {chrf_marian}")
print(f"- NLLB:     {chrf_nllb}")
print(f"- Tower:    {chrf_tower}")